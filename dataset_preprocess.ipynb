{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size = 6 color = 'tomato'>Sentinel remote sensing image preprocess for image segmentation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import earthpy.plot as ep\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "\n",
    "\n",
    "from sklearn import cluster\n",
    "from osgeo import gdal, gdal_array\n",
    "\n",
    "# Tell GDAL to throw Python exceptions, and register all drivers\n",
    "gdal.UseExceptions()\n",
    "gdal.AllRegister()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Sentinel remote sensing images using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters in sentinel_download.py\n",
    "# %run ./utils/sentinel_data_download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip the compressed dataset files (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#! usr/bin/bash\n",
    "echo \"Hello World\"\n",
    "source_files_path = \"./WHUS2-CD-DATA/Hungary_sentinel2-A/\"\n",
    "dest_files_path = \"./WHUS2-CD-DATA/Hungary_sentinel2-A/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentinel Data\n",
    "S_sentinel_bands = glob(\"/home/morin/morui/RESO/Code/Satellite_Imagery_Analysis-main/Data/L2A_data/S2A*.SAFE/GRANULE/L2A_*/IMG_DATA/R60m/*B?*.jp2\")\n",
    "S_sentinel_bands.sort()\n",
    "len(S_sentinel_bands)/11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将原始文件解压缩成SAFE包, 读取csv文件分别对训练集和测试集的数据处理, 同时将同一数据的相同分辨率的图像通道进行合并、切割并保存,最终的效果如下.\n",
    "\"\n",
    "dataset/\n",
    "├── labels\n",
    "│   ├── test_img1.tif\n",
    "│   └── train_img1.tif\n",
    "├── test\n",
    "│   ├── 10m\n",
    "│   │   └── test_img1.tif\n",
    "│   ├── 20m\n",
    "│   │   └── test_img1.tif\n",
    "│   └── 60m\n",
    "│       └── test_img1.tif\n",
    "└── train\n",
    "    ├── 10m\n",
    "    │   └── trian_img1.tif\n",
    "    ├── 20m\n",
    "    │   └── trian_img1.tif\n",
    "    └── 60m\n",
    "        └── train_img1.tif\n",
    "\n",
    "11 directories, 6 files\n",
    "\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc08e9896cc3270b5ff486dbaa0634e516bb97231cc0e56aafea69e4e7e153b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
